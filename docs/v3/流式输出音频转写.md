
# 功能描述：流式转写与实时结果展示 (Streaming Transcription)

## 1. 核心目标

改变原有“等待全部完成才显示结果”的模式，实现**边转写、边入库、边展示**。用户在长音频（如 1 小时）转写开始后数秒内即可看到第一句结果，且页面刷新不丢失数据。

## 2. 技术方案：逻辑流式 (Logical Streaming)

采用 **Python Stdout 流式输出** + **Node.js 增量写入** + **前端轮询读取** 的架构。不进行音频物理切分。

---

## 3. 后端详细设计

### 3.1 AI Worker (Python)

* **输出协议**：不再等待所有 segments 生成完毕。在遍历 `model.transcribe` 生成器时，**每生成一个 segment**，立即向 Stdout 打印一行 JSON。
* **JSON 格式**：
```json
{"type": "segment", "data": {"start": 0.0, "end": 2.5, "text": "Hello world"}}

```


* **关键要求**：必须使用 `print(..., flush=True)` 确保缓冲区立即刷新，不堆积。

### 3.2 服务层 (Node.js)

* **流监听**：
* 使用 `readline` 模块监听 Python 子进程的 `stdout`。


* **数据缓冲与入库 (Throttling)**：
* **缓冲池**：在内存中维护一个 `currentSegments` 数组。
* **防抖写入**：不要每收到一行就写数据库（I/O 太高）。
* **策略**：每收到 **5 个 segment** 或 距离上次写入超过 **2 秒**，触发一次 DB 更新。


* **数据库操作**：
* 执行 `UPDATE transcriptions SET content = ? WHERE id = ?`。
* 将内存中完整的 `currentSegments` 序列化为 JSON 存入。



---

## 4. 前端详细设计 (React)

### 4.1 数据获取

* **轮询策略**：当项目状态为 `transcribing` 时，每隔 **3 秒** 调用一次 `GET /api/projects/:id/transcription`。
* **增量渲染**：API 返回的数据包含当前已生成的完整数组（如 [0...50] 句）。前端直接替换旧数据进行渲染（React 的 Diff 算法会高效处理）。

### 4.2 交互体验

* **加载状态**：在当前结果列表的最下方，显示一个“正在生成更多...”的 Loading 动画或占位符，提示用户转写仍在继续。

---

## 5. 异常处理

* **中断恢复**：由于数据实时入库，若服务意外重启，已转写的 50% 内容保留在数据库中。用户重试时，建议清除旧数据重新开始（保持逻辑简单），或未来实现断点续传。
* **脏数据清洗**：每次**新开始**转写任务时，必须先清空该 ID 对应的旧 `content`，防止新旧数据混淆。

---

## 6. 开发任务清单 (Checklist)

* [ ] **Python**: 修改循环，改为逐个 segment `print` 并 `flush`。
* [ ] **Node**: 引入 `readline` 处理流，实现内存数组累加 + 防抖写库逻辑。
* [ ] **API**: 确保 `GET` 接口在转写未完成（status=transcribing）时也能返回数据库里已有的 content。
* [ ] **Frontend**: 实现 `setInterval` 轮询逻辑，并在状态变为 `completed` 后停止轮询。