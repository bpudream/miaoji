# 流式输出同步翻译实现总结

本文档总结“流式转写 + 同步翻译（批量）”功能的实现方式、实现范围、与现有系统的匹配情况，以及潜在风险评估。

## 1. 功能目标

- 转写流式输出时，可手动开启/关闭“同步翻译”。
- 翻译按配置的批量大小执行；不足一批且转写未结束则等待，转写结束后扫尾补齐。
- 自动从已翻译的断点继续，无需人工记录断点。
- 旧数据不迁移，仅新任务生效。

## 2. 实现概览

### 2.1 数据库结构

新增分段表，并为同步翻译引入状态字段：

- `transcription_segments`：存每一句原文（segment_index、时间戳、文本）。
- `translation_segments`：存对应译文（language + segment_index 唯一约束）。
- `transcriptions` 新增：
  - `stream_translate_enabled`
  - `stream_translate_status`（idle/processing/waiting/completed/paused/error）
  - `stream_translate_language`
  - `stream_translate_updated_at`
  - `stream_translate_error`

相关文件：`server/src/db.ts`

### 2.2 流式写入

Python worker 输出 `segment` 时，Node 端立即写入 `transcription_segments`，同时维持旧 JSON 内容（保证旧接口与 UI 兼容）。

相关文件：`server/src/queue.ts`

### 2.3 同步翻译调度器

新增调度器（每 3 秒 tick）：

- 选择 `stream_translate_enabled = 1` 的转写任务。
- 计算 gap：`max(transcription_segments) - max(translation_segments)`。
- 规则：
  - gap >= batch：立即翻译下一批。
  - gap < batch 且转写未结束：等待。
  - 转写完成：翻完剩余。
- 使用上一批末尾 N 句作为上下文，提高连贯性。
- 译文写回 `translation_segments`（幂等 upsert）。

相关文件：`server/src/services/translation.ts`

### 2.4 API

新增接口：

- `GET /api/projects/:id/transcription/segments?language=xx`  
  返回 segment 原文 + 译文（LEFT JOIN）。
- `POST /api/projects/:id/transcription/stream-translate`  
  启用/关闭同步翻译并记录状态。

相关文件：`server/src/app.ts`

### 2.5 前端

前端支持：

- 同步翻译开关按钮 + 状态提示。
- 流式译文渲染（基于 segments 接口）。
- LLM 设置增加“流式批量大小/上下文行数”配置。

相关文件：

- `web/src/components/transcription/TranscriptionPanel.tsx`
- `web/src/components/transcription/TranslationView.tsx`
- `web/src/components/LLMConfigCard.tsx`
- `web/src/lib/api.ts`

## 3. 与现有设计的兼容性

### 3.1 与旧数据的关系

- 旧 `transcriptions.content` 不再用于新任务，但仍保留写入逻辑，保证旧 UI 与导出/编辑功能可用。
- 启动新转写时会清空历史 `transcriptions`、`transcription_segments`、`translation_segments`，避免数据污染。

### 3.2 与现有翻译功能的关系

- 原有“整段翻译”功能仍在，可与同步翻译并存。
- 同步翻译使用分段表；整段翻译使用 `translations` 表，不冲突。
- 前端在同步翻译开启时优先使用流式 segments 数据；关闭时回落到原有翻译逻辑。

### 3.3 与转写流程的关系

- 仅在转写流中增加分段写入，不改动转写核心逻辑与 worker 通信协议。
- 不改变转写状态机（media_files.status），仅附加分段数据。

## 4. 潜在问题与风险评估

### 4.1 GPU 负载与性能

同时转写 + 翻译会竞争 GPU 资源，可能导致：

- 转写延迟上升
- 翻译吞吐下降
- 总体耗时变长

缓解：默认关闭同步翻译；批量配置可调；可在 LLM 配置中下调批量或上下文。

### 4.2 状态刷新延迟

同步翻译状态当前仅在开关操作与服务端调度器内部更新，前端刷新依赖轮询 segments 数据。

可优化点：增加状态查询接口或在 segments 接口中返回当前状态。

### 4.3 转写中途手工编辑

编辑转写内容时会重新生成 `transcription_segments`，但不会自动触发同步翻译补翻。若需要“编辑后重翻”，建议先关闭同步翻译，再重新开启一次。

### 4.4 翻译一致性

批量翻译虽有上下文补充，但仍可能出现分段语境偏差，属于分段翻译的常见问题。

可继续优化：提高 context lines、加入术语表/缓存、或在完成后做一轮“整体润色”。

## 5. 是否满足正常使用

总体满足：

- 支持流式转写期间手工开关翻译。
- 自动断点续翻，不会重复翻译。
- 批量翻译策略可配置。
- 数据结构清晰，可扩展多语言。

若对性能或译文一致性要求更高，可进一步：

- 增加后台限流策略
- 针对实时翻译使用更小模型或分层策略
- 追加“最终合并润色”步骤

## 6. 总结

本实现与现有系统结构兼容，逻辑解耦清晰，支持流式转写与同步翻译并行，无需迁移旧数据。当前方案已能满足正常使用场景，并留有良好扩展空间。
