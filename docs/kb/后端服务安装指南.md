# 后端服务安装指南（面向软件用户）

> 面向需要在客户或生产环境落地后端服务的实施 / 运维人员。假设已经从开发团队拿到 `release/` 目录（由 `package.bat` 生成）以及模型文件。

---

## 1. 前置依赖

### 1.1 推荐运行环境

| 项目 | 要求 |
| --- | --- |
| 操作系统 | Windows 10/11 64-bit（管理员权限）|
| CPU | 至少 4 核 |
| 内存 | ≥ 8 GB（含模型建议 16 GB）|
| 磁盘 | ≥ 20 GB（包含 Whisper 模型 ~6 GB）|
| 网络 | 可访问 npm registry（或有离线包）|

### 1.2 必备软件

| 组件 | 说明 | 校验方式 |
| --- | --- | --- |
| Node.js 18+ | 用于运行后端 | `node -v` |
| npm | 随 Node 安装 | `npm -v` |
| Python 3.9+ | 供 `python/worker.py` 使用 | `python --version` |
| pip | 安装 `faster-whisper` | `pip --version` |
| FFmpeg | 负责音频处理，需加入 PATH | `ffmpeg -version` |
| Ollama | 提供 LLM 能力，需已下载模型 | `ollama list` |
| （可选）CUDA/cuDNN | 若使用 GPU 推理 |

> 如果缺少 NSSM，可在 release 根目录执行 `tools\download-nssm.bat`（会自动放置到 `release\tools\nssm.exe`）。在源码仓库中则位于 `server\tools\download-nssm.bat`。

### 1.3 发布包结构（交付物）

```
release/
├── server/          # 服务主体（运行时在此目录）
│   ├── dist/
│   ├── python/
│   ├── data/ uploads/
│   ├── package.json / package-lock.json
│   └── env.template
├── scripts/         # 安装依赖 / 服务管理脚本
├── tools/           # NSSM 及下载脚本
└── models/
    └── large-v3/    # Whisper 模型
```

> `release/` 整体可放置于任意磁盘，例如 `D:\miaoji-backend\release\...`。

---

## 2. 安装步骤总览

| 步骤 | 目标 | 命令 / 动作 |
| --- | --- | --- |
| Step 1 | 解压并放置目录 | 将 `release/` 复制到目标路径 |
| Step 2 | 配置 `.env` | 从 `env.template` 复制并填写 |
| Step 3 | 准备系统依赖 | 安装 FFmpeg、Ollama、模型 |
| Step 4 | 安装依赖 (Node & Python) | `scripts\install-dependencies.bat` |
| Step 5 | 启动或注册服务 | `npm start` 或 `scripts\install-service.bat` |
| Step 6 | 验证 | 调用健康检查、检查日志 |

> 下文默认在 release 根目录运行 `scripts\*.bat`、`tools\*.bat`；若你位于 `release/server` 内，请在命令前添加 `..\`。

---

## 3. 详细操作

### 3.1 Step 1：准备目录

1. 选择一个工作目录（示例：`D:\apps\miaoji`）。
2. 将开发者提供的完整 `release` 目录复制到该路径，保持原有层级。
3. 确认 `release/models/large-v3` 体积与原始模型一致（约数 GB），避免拷贝损坏。

### 3.2 Step 2：配置环境变量

1. 复制模板（在 `release/server` 下）：
   ```powershell
   cd release\server
   copy env.template .env
   ```
2. 打开 `.env`，至少确认以下键值：
   ```
   BACKEND_PORT=3000
   PYTHON_WORKER_PATH=python\worker.py
   PYTHON_PATH=python\.venv\Scripts\python.exe   # 默认指向自动创建的虚拟环境
   MODEL_PATH=..\models\large-v3
   OLLAMA_HOST=http://127.0.0.1:11434
   ```
3. 若使用自定义端口或代理，请同步更新前端配置。

### 3.3 Step 3：系统依赖与模型

1. **FFmpeg**：下载官方静态包，解压后把 `bin` 目录加入 PATH。
2. **Ollama**：安装并下载所需模型（如 `ollama run llama3`），确保命令 `ollama list` 可返回模型。
3. **Whisper 模型**：保持模型目录与 `release/server` 同级，例如：
   ```
   D:\apps\miaoji\release\server
   D:\apps\miaoji\release\models\large-v3
   ```
4. (可选) **CUDA**：若启用 GPU，请按照官方指引安装驱动与库。

### 3.4 Step 4：安装依赖 (一键安装)

在 `release` 根目录执行：

```powershell
cd release
scripts\install-dependencies.bat
```

> 脚本功能：
> 1. 自动安装 Node.js 运行依赖。
> 2. 自动检测 `python` 目录，创建 `.venv` 虚拟环境。
> 3. 自动安装 Python 依赖（优先读取 `requirements.txt`，否则安装 `faster-whisper`）。

如果脚本执行成功（显示 `[SUCCESS] All Setup Steps Completed!`），则 Node 和 Python 环境均已准备就绪。

### 3.5 Step 5：启动或注册服务

#### 方式 A：直接运行（调试/一次性场景）

```powershell
cd release\server
npm start
```

日志会直接输出到当前终端，可用 `Ctrl+C` 结束。

#### 方式 B：注册为 Windows 服务（推荐生产）

1. 确保满足：
   - 以管理员身份运行 PowerShell / CMD。
   - `release/server/dist/app.js` 存在。
   - `release/tools/nssm.exe` 可用（若无，执行 `tools\download-nssm.bat`）。
2. 执行（推荐在 release 根目录）：
   ```powershell
   cd release
   scripts\install-service.bat
   ```
3. 按提示确认：
   - 脚本会检测 Node、NSSM、`.env`，并创建 `MiaojiBackend` 服务。
   - 可选择立即启动服务。
4. 常用命令（在 release 根目录执行；或从 server 内调用 `..\scripts\xxx.bat`）：
   ```powershell
   scripts\start-service.bat      # 启动
   scripts\stop-service.bat       # 停止
   scripts\restart-service.bat    # 重启
   scripts\uninstall-service.bat  # 卸载（需管理员）
   ```
5. 查看日志：
   ```powershell
   cd release\server
   type logs\service-out.log
   type logs\service-err.log
   ```

### 3.6 Step 6：健康检查

1. 端口连通：
   ```powershell
   curl http://localhost:3000/api/health
   ```
2. 日志检查：确认 `logs\service-out.log` 中包含 `Server started` 或类似信息。
3. 若前端已部署，可在前端页面发起一次处理请求进行端到端验证。

---

## 4. 常用脚本速查

| 脚本 | 功能 | 备注 |
| --- | --- | --- |
| `scripts\install-dependencies.bat` | 一键安装 Node 和 Python 依赖 | 需网络 |
| `scripts\install-service.bat` | 注册 Windows 服务 | 需管理员、NSSM |
| `scripts\start-service.bat` | 启动服务 | 可在任意目录执行 |
| `scripts\stop-service.bat` | 停止服务 | 同上 |
| `scripts\restart-service.bat` | 重启服务 | 同上 |
| `scripts\uninstall-service.bat` | 卸载服务 | 需管理员 |
| `scripts\verify-paths.bat` | 检查路径、依赖是否齐全 | 调试用 |
| `tools\download-nssm.bat` | 下载 NSSM | 需网络 |

---

## 5. 常见问题与排查

### 5.1 `scripts\install-dependencies.bat` 失败

- **Node 报错**：确认 `node -v` 正常，必要时重新安装 Node.js。
- **Python 报错**：脚本会自动跳过 Python 安装失败的部分，您可以手动进入 `release\server\python`，执行 `python -m venv .venv` 和 `pip install -r requirements.txt`。
- **网络问题**：检查网络或代理，必要时设置 `npm config set proxy` 或 `pip config set global.index-url ...`。

### 5.2 服务安装时报错 “NSSM not found”

- 执行 `tools\download-nssm.bat` 自动下载。
- 或手动从 <https://nssm.cc/download> 获取 `nssm.exe` 放到 `tools\`。

### 5.3 服务启动后立刻退出

- 查看 `logs\service-err.log`。
- 检查 `.env` 中的路径（尤其是 `MODEL_PATH`、`PYTHON_PATH`）。
- 确认为目标端口未被占用：`netstat -ano | findstr :3000`。

### 5.4 Python Worker 报错

- 激活对应虚拟环境，重新安装 `faster-whisper`。
- 确保模型目录可访问。

### 5.5 与 Ollama 交互失败

- 运行 `ollama serve` / 确保服务启动。
- 校验 `.env` 中 `OLLAMA_HOST` 地址与端口。
- 在服务器上尝试 `curl http://127.0.0.1:11434/api/tags`。

---

## 6. 升级与维护

1. **升级服务代码**
   - 停止服务：`scripts\stop-service.bat` 或 `net stop MiaojiBackend`。
   - 替换 `release/server`、`release/models`（或覆盖变更文件）。
   - 重新运行 `scripts\install-dependencies.bat`（若依赖有变化）。
   - 重启服务。
2. **更新 `.env`**
   - 修改后执行 `scripts\restart-service.bat`，让新配置生效。
3. **日志轮转**
   - NSSM 已配置按天/容量轮转，可定期清理 `logs\`。
4. **备份数据**
   - `data/` 目录内的 SQLite (`miaoji.db`) 为核心数据，建议纳入备份策略。

---

## 7. 支持与参考

- 若遇到无法解决的问题，请将以下信息提供给开发团队：
  - `logs\service-out.log` 与 `logs\service-err.log`
  - `.env`（脱敏后）或关键变量
  - Node/Python/FFmpeg/Ollama 版本信息
  - 复现步骤与截图
- 参考文档：
  - `docs/kb/后端打包指南`（了解发布包如何生成）
  - `server/scripts/README-SERVICE.md`（Windows 服务高级说明）

祝安装顺利！如需现场协助，请联系研发支持。
